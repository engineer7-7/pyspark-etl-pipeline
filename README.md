# pyspark-etl-pipeline
End-to-end PySpark ETL pipeline using DataFrames for cleaning, enrichment, analytics, and export. Includes schema definition, joins, aggregations, and final dataset extraction.


PySpark ETL Pipeline

An end-to-end PySpark data engineering project showcasing data ingestion, cleaning, enrichment, transformations, aggregations, and final dataset extraction.

This project demonstrates essential Data Engineering skills using Apache Spark and PySpark DataFrames.

ðŸ§± Project Architecture

Input â†’ Clean â†’ Enrich â†’ Transform â†’ Aggregate â†’ Export

raw CSVs
    â†“
schema definition (StructType)
    â†“
data cleaning & type casting
    â†“
data enrichment (JOIN with customers)
    â†“
transformations (new columns, normalization)
    â†“
analytics aggregations (SUM, AVG, COUNT)
    â†“
final dataset export (CSV)
